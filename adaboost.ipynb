{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. -1. -1. -1.  1.  1.  1. -1.]\n",
      "0.916515138991\n",
      "[ 0.07142857  0.07142857  0.07142857  0.07142857  0.07142857  0.07142857\n",
      "  0.16666667  0.16666667  0.16666667  0.07142857]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.arange(0,10)\n",
    "y = np.ones(len(X))\n",
    "musk_y = [3,4,5,9]\n",
    "y[musk_y] = -1\n",
    "print(y)\n",
    "def weak_classifier(m):\n",
    "    y_predict = np.ones(len(X))\n",
    "    for indx, x in enumerate(X):\n",
    "        if(x > m):\n",
    "            y_predict[indx] = -1\n",
    "    return y_predict\n",
    "\n",
    "def get_err_rate(y, y_pred):\n",
    "    return 1 - len(y[y != y_predict])/len(y)\n",
    "\n",
    "def get_coef_wc(err_rate):\n",
    "    return 0.5 * np.log(1/err_rate - 1)\n",
    "\n",
    "def get_normal_factor(Weights,cofe_wc, y, y_pred):\n",
    "    return np.dot(Weights,np.exp(-coef_wc * y * y_pred))\n",
    "\n",
    "def update_w(Weights,normal_factor,cofe_wc, y, y_pred):\n",
    "    w = Weights\n",
    "    for i in range(len(X)):\n",
    "        w[i] = w[i]/ normal_factor * np.exp(-coef_wc*y[i]*y_pred[i])\n",
    "    return w\n",
    "W = np.ones(len(X))/len(X)\n",
    "y_predict = weak_classifier(2.5)\n",
    "coef_wc = get_coef_wc(0.3)\n",
    "normal_factor = get_normal_factor(W, coef_wc,y, y_predict)\n",
    "print(normal_factor)\n",
    "print(update_w(W, normal_factor, coef_wc,y, y_predict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "def loadSimpData():\n",
    "    # pred [-1, 1, -1,-1,1]   [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    datMat = np.matrix([[ 1. ,  2.1],   \n",
    "        [ 2. ,  1.1],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat,classLabels\n",
    "\n",
    "def loadData():\n",
    "    X = np.arange(0,10)\n",
    "    y = np.ones(len(X))\n",
    "    musk_y = [3,4,5,9]\n",
    "    y[musk_y] = -1\n",
    "    return X,y\n",
    "\n",
    "datMat,classLabels = loadSimpData()\n",
    "#datMat,classLabels = loadData()\n",
    "\n",
    "print(datMat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D:  [[ 0.2  0.2  0.2  0.2  0.2]]\n",
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "shape: [-1.  1. -1. -1.  1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.2\n",
      " D:  [[ 0.5    0.125  0.125  0.125  0.125]]\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "shape: [ 1.  1. -1. -1. -1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.2\n",
      " D:  [[ 0.28571429  0.07142857  0.07142857  0.07142857  0.5       ]]\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "shape: [ 1.  1.  1.  1.  1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.4\n",
      " D:  [[ 0.16666667  0.04166667  0.25        0.25        0.29166667]]\n",
      "aggClassEst:  [[ 0.37096867  3.36670095 -1.57494148 -1.57494148  1.4207908 ]]\n",
      "shape: [-1.  1. -1. -1.  1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.2\n",
      " D:  [[ 0.5    0.025  0.15   0.15   0.175]]\n",
      "aggClassEst:  [[ 1.14626738  4.14199965 -2.35024018 -2.35024018  0.64549209]]\n",
      "shape: [ 1.  1. -1. -1. -1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.2\n",
      " D:  [[ 0.3030303   0.01515152  0.09090909  0.09090909  0.5       ]]\n",
      "aggClassEst:  [[ 1.89830608  4.89403835 -1.59820148 -1.59820148  1.39753079]]\n",
      "shape: [ 1.  1.  1.  1.  1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.4\n",
      " D:  [[ 0.18518519  0.00925926  0.25        0.25        0.30555556]]\n",
      "aggClassEst:  [[ 1.15750381  5.63484062 -2.33900375 -2.33900375  2.13833306]]\n",
      "shape: [-1.  1. -1. -1.  1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.2\n",
      " D:  [[ 0.5         0.00568182  0.15340909  0.15340909  0.1875    ]]\n",
      "aggClassEst:  [[ 1.89067234  6.36800916 -3.07217229 -3.07217229  1.40516453]]\n",
      "shape: [ 1.  1. -1. -1. -1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.2\n",
      " D:  [[ 0.30769231  0.0034965   0.09440559  0.09440559  0.5       ]]\n",
      "aggClassEst:  [[ 2.619549    7.09688582 -2.34329563 -2.34329563  2.13404119]]\n",
      "shape: [ 1.  1.  1.  1.  1.] [ 1.  1. -1. -1.  1.]\n",
      "total error:  0.4\n",
      "[{'dim': 0, 'alpha': 0.69314718055994529, 'thresh': 1.3, 'ineq': 'lt'}, {'dim': 1, 'alpha': 0.9729550745276565, 'thresh': 1.0, 'ineq': 'lt'}, {'dim': 0, 'alpha': 0.89587973461402726, 'thresh': 0.90000000000000002, 'ineq': 'lt'}, {'dim': 0, 'alpha': 0.80471895621704992, 'thresh': 1.3, 'ineq': 'lt'}, {'dim': 1, 'alpha': 0.7752987062055835, 'thresh': 1.0, 'ineq': 'lt'}, {'dim': 0, 'alpha': 0.75203869838813697, 'thresh': 0.90000000000000002, 'ineq': 'lt'}, {'dim': 0, 'alpha': 0.74080227046210767, 'thresh': 1.3, 'ineq': 'lt'}, {'dim': 1, 'alpha': 0.73316853439671337, 'thresh': 1.0, 'ineq': 'lt'}, {'dim': 0, 'alpha': 0.72887666255101768, 'thresh': 0.90000000000000002, 'ineq': 'lt'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):#just classify the data\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    #print(\"retArray\",retArray)\n",
    "    return retArray\n",
    "\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    \n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    #print(\"shape\",dataMatrix.shape)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    #m = 5, n = 2\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0 #用于在特征的所有可能值上进行遍历\n",
    "    bestStump = {} #存储给定权重向量 D 时所得到的最佳单层决策树的信息\n",
    "    bestClassEst = np.mat(np.zeros((m, 1)))\n",
    "    minError = np.inf\n",
    "    #for i in [0]:\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:, i].min()\n",
    "        rangeMax = dataMatrix[:, i].max()\n",
    "        stepSize = ( rangeMax - rangeMin) / numSteps\n",
    "        #print(\"rangeMin\",rangeMin,\"rangeMax\",rangeMax,\"stepSize\",stepSize)\n",
    "        \n",
    "        for j in range(-1, int(numSteps) + 1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                threshVal = rangeMin + float(j) * stepSize\n",
    "                #print(threshVal)\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal )\n",
    "                #print(\"predictedVals\", predictedVals)\n",
    "                errArr = np.mat(np.ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                #print(\"errArr\", errArr)\n",
    "                #errArr中分类错误的为1，weightedError为分类错误的点权重之和\n",
    "                weightedError = (np.array(D) * np.array(errArr)).sum()\n",
    "                #print(\"weightedError type\",type(weightedError) )\n",
    "                #print(inequal,\"shreshVal\",threshVal,\"weightedError\",weightedError)\n",
    "                if weightedError < minError:\n",
    "                    minError =  weightedError\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestStump[ 'dim' ] = i\n",
    "                    bestStump[ 'thresh' ] = threshVal\n",
    "                    bestStump[ 'ineq' ] = inequal\n",
    "                    \n",
    "    return bestStump, minError, bestClassEst\n",
    "\n",
    "D = np.array([0.2,0.2,0.2,0.2,0.2])\n",
    "#D = np.ones(10)/10\n",
    "#print(buildStump(datMat,classLabels,D))\n",
    "\n",
    "def adaBoostTrain(dataArr, classLabels,numIt = 40):\n",
    "    weakClfArr = []\n",
    "    m = dataArr.shape[0]\n",
    "    D = np.mat(np.ones((m,1)) / m)\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    \n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D )\n",
    "        print(\" D: \", D.T)\n",
    "        #计算弱分类器的权重\n",
    "        #print(\"error,type:\",type(error))\n",
    "        alpha = 0.5 * np.log((1/error - 1))\n",
    "    \n",
    "        bestStump[ 'alpha' ] = alpha\n",
    "        weakClfArr.append(bestStump)\n",
    "        #print(\"classEst: \", classEst.T)\n",
    "        \n",
    "        #更新D\n",
    "        #print(\"classLabels\",np.mat(classLabels).T, \"classEst\",classEst)\n",
    "        #print(\"multi:\",np.multiply(np.mat(classLabels).T , classEst))\n",
    "        #print(\"alpha:\",type(alpha))\n",
    "        expon = np.multiply( -1 * alpha * np.mat( classLabels ).T, classEst)\n",
    "        #print(\"expon:\",expon)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D / D.sum()\n",
    "        \n",
    "        # 记录对每个样本点的类别估计的累积值\n",
    "        aggClassEst += alpha * classEst\n",
    "        print(\"aggClassEst: \", aggClassEst.T)\n",
    "        \n",
    "        # 计算分类错误率\n",
    "        classEst_ = np.array(classEst.T).reshape(m)\n",
    "        classLabels_ = np.array(classLabels)\n",
    "        print(\"shape:\",classEst_ ,classLabels_)\n",
    "        errorRate = len(classLabels_[classEst_ != classLabels_])/ m\n",
    "        print(\"total error: \", errorRate)\n",
    "        \n",
    "        # 如果完全正确，终止迭代\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClfArr\n",
    "\n",
    "print(adaBoostTrain( datMat, classLabels, 9))\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]\n",
      "第 1 次，合成分类器分类错误的数据下标为: [6, 7, 8]\n",
      "第 2 次，合成分类器分类错误的数据下标为: [3, 4, 5]\n",
      "第 3 次全部分类正确，迭代结束\n",
      "{'ineq': 'gt', 'min_err': 0.30000000000000004, 'y_pred_best': array([ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.]), 'thresh': 2.5, 'alpha': 0.42364893019360172}\n",
      "{'ineq': 'gt', 'min_err': 0.21428571428571427, 'y_pred_best': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.]), 'thresh': 8.5, 'alpha': 0.64964149206513044}\n",
      "{'ineq': 'lt', 'min_err': 0.18181818181818185, 'y_pred_best': array([-1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.]), 'thresh': 5.5, 'alpha': 0.75203869838813697}\n"
     ]
    }
   ],
   "source": [
    "#按统计学习方法重写\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "X = np.arange(0,10)\n",
    "y = np.ones(len(X))\n",
    "musk_y = [3,4,5,9]\n",
    "y[musk_y] = -1\n",
    "\n",
    "m = len(X)\n",
    "\n",
    "def weak_classify(datas, threshVal, threshIneq):#just classify the data\n",
    "    retArray = np.ones(m)\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[ datas <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[datas > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "def buildStump(datas,labels,D):\n",
    "    steps = 10.0 #用于在特征的所有可能值上进行遍历\n",
    "    best_stump = {} #存储给定权重向量 D 时所得到的最佳单层决策树的信息\n",
    "    pred_y = np.zeros(m)\n",
    "    min_err = np.inf\n",
    "    \n",
    "    x_min = datas.min()\n",
    "    x_max = datas.max()\n",
    "    step_len = (x_max - x_min + 1) / steps\n",
    "    for i in range(-1, int(steps)):\n",
    "        for inequal in ['lt', 'gt']:\n",
    "            thresh = (x_min + 0.5) + i * step_len\n",
    "            #print(\"threshVal:\",thresh)\n",
    "            y_pred = weak_classify(datas,thresh, inequal)\n",
    "            #print(\"true\",labels)\n",
    "            #print(\"pred\", y_pred)\n",
    "            err_w = get_err_rate(labels, y_pred, D)\n",
    "            #print(\"inequal:\",inequal,\"err_w:\",err_w)\n",
    "            if err_w < min_err:\n",
    "                min_err =  err_w\n",
    "                best_stump['min_err'] = min_err\n",
    "                best_stump['y_pred_best'] = y_pred.copy()\n",
    "                #bestStump[ 'dim' ] = i\n",
    "                best_stump['alpha'] = get_alpha(min_err)\n",
    "                best_stump[ 'thresh' ] = thresh\n",
    "                best_stump[ 'ineq' ] = inequal\n",
    "    return best_stump\n",
    "\n",
    "def get_err_rate(y, y_pred,D):\n",
    "    pred_result = np.array(y != y_pred,dtype = np.float32)\n",
    "    #print(\"t or f:\",y != y_pred)\n",
    "    return np.dot(D,pred_result)\n",
    "\n",
    "def get_err_index(y, y_pred):\n",
    "    indx = []\n",
    "    for i in range(len(y)):\n",
    "        if(y[i] !=  y_pred[i]):\n",
    "            indx.append(i)\n",
    "    return indx\n",
    "#     pred_result = np.array(y != y_pred,dtype = np.float32)\n",
    "#     indx = np.where(pred_result == 1.0)\n",
    "#     return indx\n",
    "\n",
    "def get_alpha(err_rate):\n",
    "    return 0.5 * np.log(1/err_rate - 1)\n",
    "\n",
    "# def get_normal_factor(Weights,cofe_wc, y, y_pred):\n",
    "#     return np.dot(Weights,np.exp(-coef_wc * y * y_pred))\n",
    "\n",
    "def update_D(D,alpha, y, y_pred):\n",
    "    #D_new.shape:(5,1)\n",
    "    D_new = D * np.exp(-alpha * y * y_pred)\n",
    "    D_new = D_new/D_new.sum()\n",
    "    return D_new\n",
    "\n",
    "def get_combine_cls(models):\n",
    "    y_ = np.zeros(m)\n",
    "    for model in models:\n",
    "        y_ +=  model['alpha'] * model['y_pred_best']\n",
    "    y_[y_ > 0] = 1.0\n",
    "    y_[y_ < 0] = -1.0\n",
    "    return y_\n",
    "\n",
    "D = np.ones(len(X))/len(X)\n",
    "print(D)\n",
    "\n",
    "models = [] \n",
    "iter_num = 9\n",
    "for i in range(iter_num):\n",
    "    best_stump = buildStump(X,y,D)\n",
    "    alpha = best_stump['alpha']\n",
    "    y_pred = best_stump['y_pred_best']\n",
    "    models.append(best_stump)\n",
    "    D = update_D(D,alpha,y,y_pred)\n",
    "    y_ = get_combine_cls(models)\n",
    "    indx = get_err_index(y, y_)\n",
    "    if indx:\n",
    "        print(\"第\",i+1,\"次，合成分类器分类错误的数据下标为:\",indx)\n",
    "    else:\n",
    "        print(\"第\",i+1,\"次全部分类正确，迭代结束\")\n",
    "        break\n",
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "# err_rate_w = get_err_rate(y, y_predict,D)\n",
    "# print(err_rate_w)\n",
    "# coef_wc = get_coef_wc(0.3)\n",
    "# normal_factor = get_normal_factor(W, coef_wc,y, y_predict)\n",
    "# print(normal_factor)\n",
    "# print(update_w(W, normal_factor, coef_wc,y, y_predict))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
